{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ced1d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from reservoirpy.nodes import Reservoir, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report as creport\n",
    "from imblearn.over_sampling import SMOTE \n",
    "import shap\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38a8471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, drop_original=True, prefix_sep=\"_\"):\n",
    "\n",
    "    non_numeric_cols = df.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "    \n",
    "    if not non_numeric_cols:\n",
    "        return df.copy()\n",
    "\n",
    "    df_encoded = pd.get_dummies(df, columns=non_numeric_cols, prefix_sep=prefix_sep)\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "def find_high_corr_features(df, target_col, threshold=0.9):\n",
    "\n",
    "    # Drop non-numeric columns\n",
    "    numeric_df = df.select_dtypes(include='number')\n",
    "\n",
    "    if target_col not in numeric_df.columns:\n",
    "        raise ValueError(f\"Target column '{target_col}' is not numeric or missing from the DataFrame.\")\n",
    "\n",
    "    # Compute correlations\n",
    "    corrs = numeric_df.corr()[target_col].drop(target_col)\n",
    "\n",
    "    # Find strong correlations\n",
    "    high_corr_features = corrs[abs(corrs) > threshold].sort_values(ascending=False)\n",
    "\n",
    "    if high_corr_features.empty:\n",
    "        print(\"✅ No features are correlated above the threshold.\")\n",
    "    else:\n",
    "        print(\"⚠️ High correlation detected:\")\n",
    "        print(high_corr_features)\n",
    "\n",
    "    return list(high_corr_features.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4beaeb",
   "metadata": {},
   "source": [
    "### 12 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "977e11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean_df.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['time'] = (df['date'] - df['date'].min()).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8be6e4",
   "metadata": {},
   "source": [
    "find_high_corr_features(df, 'ext_gust_window_72')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21603f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['high_wind_event','valid_time','date'], axis=1, inplace=True)\n",
    "df.drop(['ext_gust_window_48','ext_gust_window_72','ext_gust_window_168', 'ext_gust_window_720'], axis=1, inplace=True)\n",
    "df = one_hot_encode(df)\n",
    "df_y = df['ext_gust_window_12']\n",
    "df_x = df.drop(['ext_gust_window_12'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "894139cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.20, random_state=42)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a06992f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5245\n",
      "           1       0.65      0.15      0.24       103\n",
      "\n",
      "    accuracy                           0.98      5348\n",
      "   macro avg       0.82      0.57      0.61      5348\n",
      "weighted avg       0.98      0.98      0.98      5348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# base\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(creport(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfe7ab78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Reservoir-9: 100%|██████████████████████████████████████████████████████████| 21390/21390 [00:41<00:00, 517.12it/s]\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Running Reservoir-9: 100%|████████████████████████████████████████████████████████████| 5348/5348 [00:10<00:00, 504.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5245\n",
      "           1       0.83      0.76      0.79       103\n",
      "\n",
      "    accuracy                           0.99      5348\n",
      "   macro avg       0.91      0.88      0.89      5348\n",
      "weighted avg       0.99      0.99      0.99      5348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reservoir = Reservoir(units=5000, sr=0.8)  \n",
    "X_train_reservoir = reservoir.run(X_train, reset=True)  \n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_reservoir, y_train)\n",
    " \n",
    "X_test_reservoir = reservoir.run(X_test, reset=True)\n",
    "y_pred_probs = classifier.predict_proba(X_test_reservoir)[:, 1] \n",
    "y_pred = (y_pred_probs > 0.5).astype(int) \n",
    "\n",
    "print(creport(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed7b695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "524fe1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "x, y = make_hastie_10_2(n_samples=24000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b952c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0 if i == -1 else 1 for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17281a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be019a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Reservoir-10: 100%|█████████████████████████████████████████████████████████| 19200/19200 [00:32<00:00, 597.35it/s]\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Running Reservoir-11: 100%|███████████████████████████████████████████████████████████| 4800/4800 [00:08<00:00, 596.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.38      0.42      2439\n",
      "           1       0.47      0.57      0.51      2361\n",
      "\n",
      "    accuracy                           0.47      4800\n",
      "   macro avg       0.47      0.47      0.47      4800\n",
      "weighted avg       0.47      0.47      0.47      4800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reservoir = Reservoir(units=5000, sr=0.8)  \n",
    "X_train_reservoir = reservoir.run(X_train, reset=True)  \n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_reservoir, y_train)\n",
    "\n",
    "reservoir = Reservoir(units=5000, sr=0.8)  \n",
    "X_test_reservoir = reservoir.run(X_test, reset=True)\n",
    "y_pred_probs = classifier.predict_proba(X_test_reservoir)[:, 1] \n",
    "y_pred = (y_pred_probs > 0.5).astype(int) \n",
    "\n",
    "\n",
    "print(creport(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20e4cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55673fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 48 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65a627d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean_df.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['time'] = (df['date'] - df['date'].min()).dt.total_seconds() / 3600\n",
    "\n",
    "df.drop(['high_wind_event','valid_time','date'], axis=1, inplace=True)\n",
    "df.drop(['ext_gust_window_12','ext_gust_window_72','ext_gust_window_168', 'ext_gust_window_720'], axis=1, inplace=True)\n",
    "df = one_hot_encode(df)\n",
    "df_y = df['ext_gust_window_48']\n",
    "df_x = df.drop(['ext_gust_window_48'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ae11bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.20, random_state=42)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c893eafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Reservoir-12: 100%|█████████████████████████████████████████████████████████| 21390/21390 [00:41<00:00, 510.14it/s]\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Running Reservoir-12: 100%|███████████████████████████████████████████████████████████| 5348/5348 [00:10<00:00, 510.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5223\n",
      "           1       0.85      0.86      0.86       125\n",
      "\n",
      "    accuracy                           0.99      5348\n",
      "   macro avg       0.92      0.93      0.93      5348\n",
      "weighted avg       0.99      0.99      0.99      5348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reservoir = Reservoir(units=5000, sr=0.8)  \n",
    "X_train_reservoir = reservoir.run(X_train, reset=True)  \n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_reservoir, y_train)\n",
    "\n",
    "X_test_reservoir = reservoir.run(X_test, reset=True)\n",
    "y_pred_probs = classifier.predict_proba(X_test_reservoir)[:, 1] \n",
    "y_pred = (y_pred_probs > 0.5).astype(int) \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(creport(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41a7b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 72 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d791107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean_df.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['time'] = (df['date'] - df['date'].min()).dt.total_seconds() / 3600\n",
    "\n",
    "df.drop(['high_wind_event','valid_time','date'], axis=1, inplace=True)\n",
    "df.drop(['ext_gust_window_12','ext_gust_window_48','ext_gust_window_168', 'ext_gust_window_720'], axis=1, inplace=True)\n",
    "df = one_hot_encode(df)\n",
    "df_y = df['ext_gust_window_72']\n",
    "df_x = df.drop(['ext_gust_window_72'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d4b2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.20, random_state=42)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c1654c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Reservoir-13: 100%|█████████████████████████████████████████████████████████| 21390/21390 [00:41<00:00, 516.28it/s]\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Running Reservoir-13: 100%|███████████████████████████████████████████████████████████| 5348/5348 [00:10<00:00, 517.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5138\n",
      "           1       0.91      0.92      0.91       210\n",
      "\n",
      "    accuracy                           0.99      5348\n",
      "   macro avg       0.95      0.96      0.96      5348\n",
      "weighted avg       0.99      0.99      0.99      5348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reservoir = Reservoir(units=5000, sr=0.8)  \n",
    "X_train_reservoir = reservoir.run(X_train, reset=True)  \n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_reservoir, y_train)\n",
    "\n",
    "X_test_reservoir = reservoir.run(X_test, reset=True)\n",
    "y_pred_probs = classifier.predict_proba(X_test_reservoir)[:, 1] \n",
    "y_pred = (y_pred_probs > 0.5).astype(int) \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(creport(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fddd1d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 168 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42f70732",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean_df.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['time'] = (df['date'] - df['date'].min()).dt.total_seconds() / 3600\n",
    "\n",
    "df.drop(['high_wind_event','valid_time','date'], axis=1, inplace=True)\n",
    "df.drop(['ext_gust_window_12','ext_gust_window_48','ext_gust_window_72', 'ext_gust_window_720'], axis=1, inplace=True)\n",
    "df = one_hot_encode(df)\n",
    "df_y = df['ext_gust_window_168']\n",
    "df_x = df.drop(['ext_gust_window_168'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da02b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.20, random_state=42)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7627910b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Reservoir-14: 100%|█████████████████████████████████████████████████████████| 21390/21390 [00:42<00:00, 508.84it/s]\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Running Reservoir-15: 100%|███████████████████████████████████████████████████████████| 5348/5348 [00:10<00:00, 504.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.61      0.73      4895\n",
      "           1       0.08      0.39      0.14       453\n",
      "\n",
      "    accuracy                           0.59      5348\n",
      "   macro avg       0.50      0.50      0.43      5348\n",
      "weighted avg       0.84      0.59      0.68      5348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reservoir = Reservoir(units=5000, sr=0.8)  \n",
    "X_train_reservoir = reservoir.run(X_train, reset=True)  \n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_reservoir, y_train)\n",
    "\n",
    "reservoir = Reservoir(units=5000, sr=0.8)  \n",
    "X_test_reservoir = reservoir.run(X_test, reset=True)\n",
    "y_pred_probs = classifier.predict_proba(X_test_reservoir)[:, 1] \n",
    "y_pred = (y_pred_probs > 0.5).astype(int) \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(creport(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4222020",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7616250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/clean_df.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['time'] = (df['date'] - df['date'].min()).dt.total_seconds() / 3600\n",
    "\n",
    "df.drop(['high_wind_event','valid_time','date'], axis=1, inplace=True)\n",
    "df.drop(['ext_gust_window_12','ext_gust_window_48','ext_gust_window_72', 'ext_gust_window_168'], axis=1, inplace=True)\n",
    "df = one_hot_encode(df)\n",
    "df_y = df['ext_gust_window_720']\n",
    "df_x = df.drop(['ext_gust_window_720'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d2dfc06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.20, random_state=42)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "34908a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Reservoir-16: 100%|█████████████████████████████████████████████████████████| 21390/21390 [00:41<00:00, 511.78it/s]\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Running Reservoir-17: 100%|███████████████████████████████████████████████████████████| 5348/5348 [00:10<00:00, 509.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.61      0.72      4622\n",
      "           1       0.14      0.39      0.20       726\n",
      "\n",
      "    accuracy                           0.58      5348\n",
      "   macro avg       0.50      0.50      0.46      5348\n",
      "weighted avg       0.77      0.58      0.65      5348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reservoir = Reservoir(units=5000, sr=0.8)  \n",
    "X_train_reservoir = reservoir.run(X_train, reset=True)  \n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_reservoir, y_train)\n",
    "\n",
    "reservoir = Reservoir(units=5000, sr=0.8)  \n",
    "X_test_reservoir = reservoir.run(X_test, reset=True)\n",
    "y_pred_probs = classifier.predict_proba(X_test_reservoir)[:, 1] \n",
    "y_pred = (y_pred_probs > 0.5).astype(int) \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(creport(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b4afa3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target column 'ext_gust_window_168' is not numeric or missing from the DataFrame.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m find_high_corr_features(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mext_gust_window_168\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 18\u001b[0m, in \u001b[0;36mfind_high_corr_features\u001b[0;34m(df, target_col, threshold)\u001b[0m\n\u001b[1;32m     15\u001b[0m numeric_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m numeric_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not numeric or missing from the DataFrame.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Compute correlations\u001b[39;00m\n\u001b[1;32m     21\u001b[0m corrs \u001b[38;5;241m=\u001b[39m numeric_df\u001b[38;5;241m.\u001b[39mcorr()[target_col]\u001b[38;5;241m.\u001b[39mdrop(target_col)\n",
      "\u001b[0;31mValueError\u001b[0m: Target column 'ext_gust_window_168' is not numeric or missing from the DataFrame."
     ]
    }
   ],
   "source": [
    "find_high_corr_features(df, 'ext_gust_window_168')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605b298",
   "metadata": {},
   "source": [
    "# let's try with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c104ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9251ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state=1234, sampling_strategy=0.5)\n",
    "\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32bbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "reservoir = Reservoir(units=5000, sr=0.8)  \n",
    "X_train_reservoir = reservoir.run(X_train)  \n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_reservoir, y_train)\n",
    "\n",
    "X_test_reservoir = reservoir.run(X_test)\n",
    "y_pred_probs = classifier.predict_proba(X_test_reservoir)[:, 1] \n",
    "y_pred = (y_pred_probs > 0.5).astype(int) \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(creport(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as cmatrix\n",
    "print(cmatrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f99ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
